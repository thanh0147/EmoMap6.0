# build_db.py
import os
import shutil
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# ÄÆ°á»ng dáº«n (TÆ°Æ¡ng Ä‘á»‘i)
DATA_PATH = "./data_source"
DB_PATH = "./chroma_db"

def create_vector_db():
    # 1. XÃ³a DB cÅ© náº¿u cÃ³ (Ä‘á»ƒ lÃ m sáº¡ch)
    if os.path.exists(DB_PATH):
        shutil.rmtree(DB_PATH)
        print("ğŸ§¹ ÄÃ£ xÃ³a Database cÅ©.")

    # 2. Äá»c PDF
    print("â³ Äang Ä‘á»c tÃ i liá»‡u PDF...")
    loader = PyPDFDirectoryLoader(DATA_PATH)
    documents = loader.load()
    if not documents:
        print("âš ï¸ Lá»—i: KhÃ´ng tháº¥y file PDF nÃ o trong thÆ° má»¥c data_source!")
        return

    # 3. Cáº¯t nhá» vÄƒn báº£n
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… ÄÃ£ cáº¯t thÃ nh {len(chunks)} Ä‘oáº¡n nhá».")

    # 4. Táº£i Model Embeddings (LÆ¯U Ã: Pháº£i nhá»› tÃªn model nÃ y)
    print("â¬‡ï¸ Äang táº£i Model Embeddings (HuggingFace)...")
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # 5. Táº¡o vÃ  LÆ°u Database
    print("ğŸš€ Äang táº¡o Vector Database vÃ  lÆ°u vÃ o thÆ° má»¥c 'chroma_db'...")
    db = Chroma.from_documents(
        documents=chunks, 
        embedding=embedding_model, 
        persist_directory=DB_PATH
    )
    print("ğŸ‰ XONG! ThÆ° má»¥c 'chroma_db' Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ Ä‘áº©y lÃªn GitHub.")

if __name__ == "__main__":
    create_vector_db()